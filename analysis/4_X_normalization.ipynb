{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87d66378",
   "metadata": {},
   "source": [
    "# X normalization\n",
    "\n",
    "For Extended Data Fig. 4ab and 5c.\n",
    "\n",
    "This code is for evaluating the effect of normalizing proteins in X when simulating decompression.\n",
    "\n",
    "This code produces 12 Us with unique SMAF parameter conditions and for each U, 5 normalizing weight and 200 random As were used for simulating decompression.\n",
    "\n",
    "## impot libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1030d592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import anndata as ad\n",
    "from pathlib import Path\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import errno\n",
    "import itertools\n",
    "from sklearn.mixture import GaussianMixture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e0d3fa",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf332338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import system libraries to configure code directory as module\n",
    "from os.path import dirname, abspath, join\n",
    "import sys\n",
    "\n",
    "# Find code directory relative to our directory\n",
    "THIS_DIR = dirname('__file__')\n",
    "CODE_DIR = abspath(join(THIS_DIR, '..', 'code'))\n",
    "# Add code directory to systems paths\n",
    "sys.path.append(CODE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65bc1346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dictionary training fnc. (smaf)\n",
    "from smaf import smaf\n",
    "from utils import analyse_U_W, produce_random_As, analyse_decoding, is_valid_file\n",
    "from simulate_A import simulate_A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62efd6c5",
   "metadata": {},
   "source": [
    "## Input data and specify output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8086ace9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read sce data\n",
    "data_path = Path('/mnt/projects/data')\n",
    "sce_path = Path(os.path.join(data_path,'0_tissues_th182/sce/sce.h5ad'))\n",
    "\n",
    "EXP_name = 'publication/4_X_normalization'\n",
    "out_path = Path(os.path.join(data_path, EXP_name))\n",
    "U_path = Path(os.path.join(out_path, \"U\"))\n",
    "A_path = Path(os.path.join(out_path, \"A\"))\n",
    "# Create output directory if it doesn't exist\n",
    "out_path.mkdir(parents=True, exist_ok=True)\n",
    "U_path.mkdir(parents=True, exist_ok=True)\n",
    "A_path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e26e33fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that input files/dictionary exist\n",
    "if not is_valid_file(sce_path, ['.h5ad']):\n",
    "    # If file is not found, throw error\n",
    "    raise FileNotFoundError(errno.ENOENT, os.strerror(errno.ENOENT),sce_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35a56117",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/test_cisi_imc_env/lib/python3.10/site-packages/anndata/_core/anndata.py:121: ImplicitModificationWarning: Transforming to str index.\n",
      "  warnings.warn(\"Transforming to str index.\", ImplicitModificationWarning)\n"
     ]
    }
   ],
   "source": [
    "# read and subset sce with relavant markers\n",
    "sce = ad.read_h5ad(sce_path)\n",
    "\n",
    "sce = sce[:, ~sce.var.index.isin([\"panCK\",\"CD15\", \"CD11c\", \"CD56\"])]\n",
    "\n",
    "# remove whole slide tonsil and appendix data\n",
    "sce = sce[~sce.obs.tissue.isin([\"AppendixW\",\"TonsilW\"]),:]\n",
    "\n",
    "# split sce to training A and U\n",
    "X_trainingA = sce[np.random.choice(sce.shape[0], int(sce.shape[0]*0.25),replace=False),:]\n",
    "X_trainingU = sce[~sce.obs.index.isin(X_trainingA.obs.index),:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1363de57",
   "metadata": {},
   "source": [
    "## Set SMAF parameters tested\n",
    "d: initial n. of modules in U\n",
    "\n",
    "maxItr: N. of iteration for each SMAF run\n",
    "\n",
    "nthread: N. of thread\n",
    "\n",
    "l_methodW: algorithm for calculating W. \"lasso\" or \"omp_fixedk\"\n",
    "\n",
    "l_ldaU: error tolerance coefficient when calculating U.\n",
    "\n",
    "l_ldaW: error tolerance coefficient when calculating W. (only for lasso)\n",
    "\n",
    "l_nblocksW_lasso: N. of blocks to separate cells when claculating W. (only for lasso)\n",
    "\n",
    "l_k_fixedk: Sparsity of W (N. of non-zero input per cell in W) (only for omp_fixedk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5992b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "## prepare Us with different param\n",
    "# set variables\n",
    "d = 80\n",
    "maxItr = 5#100\n",
    "nthread = -1\n",
    "\n",
    "# main iterator\n",
    "l_methodW = ['lasso','omp_fixedk']\n",
    "l_ldaU = [0.2,0.02]\n",
    "\n",
    "# methodW specific iterator\n",
    "l_nblocksW_lasso = [1, 200]\n",
    "l_ldaW = [0.2,0.02]\n",
    "l_k_fixedk = [1,3] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28210b99",
   "metadata": {},
   "source": [
    "## Produce Us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96460dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized U, W with NMF, SMAF maxItr =  5\n",
      "Initialized U, W with NMF, SMAF maxItr =  5\n",
      "Initialized U, W with NMF, SMAF maxItr =  5\n",
      "Initialized U, W with NMF, SMAF maxItr =  5\n",
      "Initialized U, W with NMF, SMAF maxItr =  5\n",
      "Initialized U, W with NMF, SMAF maxItr =  5\n",
      "Initialized U, W with NMF, SMAF maxItr =  5\n",
      "Initialized U, W with NMF, SMAF maxItr =  5\n",
      "Initialized U, W with NMF, SMAF maxItr =  5\n",
      "Initialized U, W with NMF, SMAF maxItr =  5\n",
      "Initialized U, W with NMF, SMAF maxItr =  5\n",
      "Initialized U, W with NMF, SMAF maxItr =  5\n"
     ]
    }
   ],
   "source": [
    "## SMAF params\n",
    "sum_res_U = [] # results\n",
    "cond_U = [] # conditions\n",
    "expid = 0 # experiment id. Used to match results and U\n",
    "cur_ROI = \"percent25\"\n",
    "# initialize U_list \n",
    "Us = []\n",
    "\n",
    "## SMAF producing Us\n",
    "for (methodW, ldaU) in itertools.product(l_methodW,l_ldaU):\n",
    "    ldaW,k,num_blocks_W = (np.NaN,np.NaN,np.NaN) # initialize sub iterables for saving result. \n",
    "\n",
    "    if methodW == 'lasso':\n",
    "        for ldaW,num_blocks_W in itertools.product(l_ldaW,l_nblocksW_lasso):            \n",
    "            # calc U\n",
    "            U,W,X = smaf(X_trainingU,d,maxItr,methodW,ldaU, ldaW=ldaW,k=k, THREADS=nthread,  X_normalization='paper_norm',\n",
    "                      num_blocks_W=num_blocks_W, num_blocks_U=1, layer=None, Normalize_U=True, saveItr=False) \n",
    "            # get SMAF results\n",
    "            res_U, coln_U = analyse_U_W(U, W, X)\n",
    "            # save U \n",
    "            pd.DataFrame(U, columns=list(range(1, U.shape[1]+1)),index=sce.var_names).to_csv(\n",
    "                os.path.join(U_path, 'U_expid{:d}.csv'.format(expid)))\n",
    "            # append Us and results list\n",
    "            Us.append(U)    \n",
    "            sum_res_U.append(res_U)\n",
    "            cond_U.append([expid, maxItr, methodW, ldaU, num_blocks_W,ldaW,k, cur_ROI ])\n",
    "            expid += 1\n",
    "            \n",
    "    elif methodW == 'omp_fixedk':\n",
    "        for k in l_k_fixedk:\n",
    "            # calc U\n",
    "            U,W,X = smaf(X_trainingU,d,maxItr,methodW,ldaU, ldaW=ldaW,k=k, THREADS=nthread,  X_normalization='paper_norm',\n",
    "                      num_blocks_W=num_blocks_W, num_blocks_U=1, layer=None, Normalize_U=True, saveItr=False) \n",
    "            # get SMAF results\n",
    "            res_U, coln_U = analyse_U_W(U, W, X)\n",
    "            # save U \n",
    "            pd.DataFrame(U, columns=list(range(1, U.shape[1]+1)),index=sce.var_names).to_csv(\n",
    "                os.path.join(U_path, 'U_expid{:d}.csv'.format(expid)))\n",
    "            # append Us and results list\n",
    "            Us.append(U)    \n",
    "            sum_res_U.append(res_U)\n",
    "            cond_U.append([expid, maxItr, methodW, ldaU, num_blocks_W,ldaW,k, cur_ROI ])\n",
    "            expid += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e56d65f",
   "metadata": {},
   "source": [
    "## Produce random 200 As\n",
    "Here we produced random As with maxcomposition of 2\n",
    "\n",
    "n_A_each: n of random As produced per unique L0sum\n",
    "\n",
    "n_L0sum: n of unique L0 sum. Defined number of L0sum will be selected in desending order from the max L0sum.\n",
    "\n",
    "g: no of total genes\n",
    "\n",
    "m: n of composite channels\n",
    "\n",
    "n: [min,max] of channels per gene\n",
    "\n",
    "d_thresh: distance threshold per gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "36aa01c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random 4 As with L0sum between 29 and 32. 16 genes into 8 channels, max 2 channels per gene\n",
      "11 0\n"
     ]
    }
   ],
   "source": [
    "# produce Phi with maxcomposition of 2\n",
    "Phi = produce_random_As(n_A_each=1, n_L0sum=4, m=8, n=(1,2), d_thresh=0.7, g=16)#50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "186c3514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save As\n",
    "np.save(os.path.join(A_path,\"Phi.npy\"),np.array(Phi))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c56bc0",
   "metadata": {},
   "source": [
    "## GMM and L2norm for normalizing with mean intensity of positive cell population\n",
    "\n",
    "GMM is used to define and obtain mean intensity of positive cell population for each protein. Proteins in X was scaled to equalize the obtained mean intensities.\n",
    "\n",
    "L2norm (||x||_2) is used for standard normalization of X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1b6742bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate GMM for each protein\n",
    "GMMsignals = []  # mean intensity of positive cell population.\n",
    "GMMnpcells = []  # no of positive cells\n",
    "GMMsnrs = []     # (mean intensity of positive cell population)/(mean intensity of negative cell population)\n",
    "\n",
    "for marker in sce.var.index:\n",
    "    X = sce.X[:,sce.var.index==marker]\n",
    "    G = GaussianMixture(n_components=2, random_state=230420).fit_predict(X.reshape(-1, 1))\n",
    "\n",
    "    mean1 = np.mean(X[G==1])\n",
    "    mean2 = np.mean(X[G==0])\n",
    "\n",
    "    if mean1 >= mean2:\n",
    "        signal = float(mean1)\n",
    "        snr = mean1/mean2\n",
    "        npcells = np.sum(G) # number of positive cells\n",
    "\n",
    "    else:\n",
    "        signal = float(mean2)\n",
    "        snr = mean2/mean1\n",
    "        npcells = X.shape[0]-np.sum(G) # number of positive cells\n",
    "\n",
    "    GMMsignals.append(signal)    \n",
    "    GMMnpcells.append(npcells)\n",
    "    GMMsnrs.append(snr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e428b0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain average (across proteins) of mean signal intensity for scaling during normalization\n",
    "# l2norm of each gene (||x||_2) was also calculated for standard normalization\n",
    "gene_l2 = np.linalg.norm(sce.X, axis = 0)\n",
    "ave_genel2 = np.full(np.shape(sce)[1], np.mean(np.linalg.norm(sce.X, axis = 0)))\n",
    "GMMsignals = np.array(GMMsignals)\n",
    "ave_GMMsignals = np.full(np.shape(sce)[1], np.mean(GMMsignals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "42983108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the analysis results for norms of X\n",
    "df = pd.DataFrame(data = {\"GMMsignal\": GMMsignals,\n",
    "                          \"GMMnpcells\": GMMnpcells,\n",
    "                          \"GMMsnr\": GMMsnrs,\n",
    "                          \"genel2\": gene_l2,\n",
    "                          \"genel2_GMMsignal_ratio\": gene_l2/GMMsignals/(np.mean(gene_l2/GMMsignals))},\n",
    "                  index = sce.var.index)\n",
    "\n",
    "df.to_csv(path_or_buf=os.path.join(out_path, 'result_norms.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06b6235",
   "metadata": {},
   "source": [
    "## Simulate decompression with X_normalization\n",
    "### set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9358dec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Params for simulate A \n",
    "nsr = 0   \n",
    "ldaW_dc = 0.02\n",
    "# set weight for normalization (1: normalize 100%, 0: no normalize)\n",
    "wt_list = [0, 0.5, 1, \"0.5_GMM\", \"1_GMM\"]\n",
    "\n",
    "# Results container\n",
    "sum_res_A = []\n",
    "genewise_res_A = []\n",
    "\n",
    "# prep normed XforA for weighted normalization\n",
    "X_trainingA_normed = X_trainingA.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0500269",
   "metadata": {},
   "source": [
    "### simulate decompression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0df20294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/test_cisi_imc_env/lib/python3.10/site-packages/scipy/spatial/distance.py:622: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "1\n",
      "0.5_GMM\n",
      "1_GMM\n"
     ]
    }
   ],
   "source": [
    "## Simulate decompression\n",
    "for wt in wt_list:      \n",
    "    print(wt)\n",
    "    # Normalize X with weight\n",
    "    if \"_GMM\" in str(wt):\n",
    "        cwt = float(wt.split(\"_GMM\")[0])\n",
    "        normalizer = (ave_GMMsignals*(1-cwt) + GMMsignals*cwt)/ave_GMMsignals\n",
    "    else:    \n",
    "        normalizer = (ave_genel2*(1-wt) + gene_l2*wt)/ave_genel2\n",
    "    X_trainingA_normed.X = X_trainingA.X / normalizer\n",
    "    \n",
    "    # loop through Us\n",
    "    for u_id, U in enumerate(Us):\n",
    "        Mincorr = np.array([])\n",
    "        \n",
    "        # loop through As\n",
    "        for phi_id, phi in enumerate(Phi): \n",
    "            # simulate decompression\n",
    "            X, Xhat, W, Y = simulate_A(X_trainingA_normed, U, phi, nsr, decoding_lasso_lda = ldaW_dc,\n",
    "                                 outpath=None, THREADS=-1, layer=None, num_blocks=20)\n",
    "            \n",
    "            # calculate L0sum for results\n",
    "            L0sum = np.linalg.norm(phi,ord = 0, axis = 1).sum()\n",
    "            # analyse results\n",
    "            res_A, coln_A, detail_A = analyse_decoding(phi,U,W,X,Xhat, name=\"\", detail=True)\n",
    "            res_A.extend([u_id,phi_id,L0sum,nsr,ldaW_dc, wt, cur_ROI])\n",
    "            coln_A.extend([\"U_id\", \"A_id\",\"A_L0_sum\",\"inv_SNratio\",\"ldaW_simA\", \"Xnorm_weight\", \"ROI\"])\n",
    "            sum_res_A.append(res_A)\n",
    "            genewise_res_A.append(detail_A[0])\n",
    "            # for printing\n",
    "            Mincorr = np.append(Mincorr,res_A[1])\n",
    "            if (phi_id+1)%100 == 0:\n",
    "                idx = np.argsort(Mincorr)  # get sorted index\n",
    "                best5 = Mincorr[idx[-5:][::-1]] # Best 5\n",
    "                print(\"current itr: {}, top5 mincorr:\".format(phi_id) ,['{:.3f}'.format(e) for e in best5])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67f29df",
   "metadata": {},
   "source": [
    "## save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f17caab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform U results into DF\n",
    "cond_U = pd.DataFrame(cond_U)\n",
    "cond_U.columns = ['expid','maxItr', 'methodW', 'ldaU', 'num_blocks_W','ldaW','k','trainingA_ROI']\n",
    "sum_res_U = pd.DataFrame(sum_res_U)\n",
    "sum_res_U.columns = coln_U\n",
    "# combine df results and conditions\n",
    "df = sum_res_U.join(cond_U)\n",
    "# save U results as csv\n",
    "df.to_csv(path_or_buf=os.path.join(out_path, 'result_U.csv'))\n",
    "\n",
    "\n",
    "\n",
    "# Transform A results into DF\n",
    "df = pd.DataFrame(sum_res_A)\n",
    "df.columns = coln_A\n",
    "\n",
    "# save A results as csv\n",
    "df.to_csv(path_or_buf=os.path.join(out_path, 'result_A.csv'))\n",
    "\n",
    "\n",
    "# save genewise results as well\n",
    "df = pd.DataFrame(genewise_res_A)\n",
    "df.columns = sce.var.index\n",
    "df.to_csv(path_or_buf=os.path.join(out_path, 'result_A_genewise.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6742ebe4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1151da36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6be7f6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77af9dd7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_cisi_imc_env",
   "language": "python",
   "name": "test_cisi_imc_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
