{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c991a4b",
   "metadata": {},
   "source": [
    "# Max composite channels per protein in barcoding matrix\n",
    "\n",
    "For Extended Data Fig. 3\n",
    "\n",
    "This code produces random As within specified maxcomposition (Max n. ofcomposite channels per protein in barcoding matrix), and simulates decompression.\n",
    "\n",
    "Produced random As and resuts of the analysis of simulated decompression are saved.\n",
    "\n",
    "\n",
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1030d592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import anndata as ad\n",
    "from pathlib import Path\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import errno\n",
    "import itertools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf332338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import system libraries to configure code directory as module\n",
    "from os.path import dirname, abspath, join\n",
    "import sys\n",
    "\n",
    "# Find code directory relative to our directory\n",
    "THIS_DIR = dirname('__file__')\n",
    "CODE_DIR = abspath(join(THIS_DIR, '..', 'code'))\n",
    "# Add code directory to systems paths\n",
    "sys.path.append(CODE_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d867c54",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65bc1346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dictionary training fnc. (smaf)\n",
    "from smaf import smaf\n",
    "from utils import analyse_U_W, analyse_decoding, produce_random_As, is_valid_file\n",
    "from simulate_A import simulate_A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56924b85",
   "metadata": {},
   "source": [
    "## Input data and specify output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8086ace9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read sce data\n",
    "data_path = Path('/mnt/projects/data')\n",
    "sce_path = Path(os.path.join(data_path,'0_preprocess_th184/processed/sce.h5ad'))\n",
    "\n",
    "EXP_name = 'publication/3_A_maxcomposition'\n",
    "out_path = Path(os.path.join(data_path, EXP_name))\n",
    "U_path = Path(os.path.join(out_path, \"U\"))\n",
    "A_path = Path(os.path.join(out_path, \"A\"))\n",
    "# Create output directory if it doesn't exist\n",
    "out_path.mkdir(parents=True, exist_ok=True)\n",
    "U_path.mkdir(parents=True, exist_ok=True)\n",
    "A_path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e26e33fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that input files/dictionary exist\n",
    "if not is_valid_file(sce_path, ['.h5ad']):\n",
    "    # If file is not found, throw error\n",
    "    raise FileNotFoundError(errno.ENOENT, os.strerror(errno.ENOENT),sce_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35a56117",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# read and subset sce with relavant markers\n",
    "sce = ad.read_h5ad(sce_path)\n",
    "\n",
    "sce = sce[:, ~sce.var.index.isin([\"panCK\",\"CD15\", \"CD11c\", \"CD56\"])]\n",
    "\n",
    "# remove whole slide tonsil 1, 2 to reduce non-tumor immune cells\n",
    "sce = sce[~sce.obs.tissue.isin([\"Tonsil1\",\"Tonsil2\"]),:]\n",
    "\n",
    "# subset sce for training U and testing A\n",
    "perc = 0.25\n",
    "sce_trainingA = sce[np.random.choice(sce.shape[0], int(sce.shape[0]*perc),replace=False),:]\n",
    "sce_trainingU = sce[~sce.obs.index.isin(sce_trainingA.obs.index),:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e84f75",
   "metadata": {},
   "source": [
    "## Prepare dictionary for simulating decompression\n",
    "d: initial n. of modules in U\n",
    "\n",
    "maxItr: N. of iteration for each SMAF run\n",
    "\n",
    "nthread: N. of thread\n",
    "\n",
    "methodW: algorithm for calculating W. \"lasso\" or \"omp_fixedk\"\n",
    "\n",
    "ldaU: error tolerance coefficient when calculating U.\n",
    "\n",
    "ldaW: error tolerance coefficient when calculating W.\n",
    "\n",
    "nblocksW_lasso: N. of blocks to separate cells when claculating W. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5992b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized U, W with NMF, SMAF maxItr =  100\n"
     ]
    }
   ],
   "source": [
    "## prepare U\n",
    "\n",
    "## Set params for U\n",
    "# set variables\n",
    "d = 80\n",
    "maxItr = 100\n",
    "nthread = -1\n",
    "methodW = 'lasso'\n",
    "ldaU = 0.02\n",
    "nblocksW_lasso = 1\n",
    "ldaW = 0.02\n",
    "\n",
    "# calc U\n",
    "U,W,X = smaf(sce_trainingU,d,maxItr,methodW,ldaU, ldaW=ldaW, THREADS=nthread,  X_normalization='paper_norm',\n",
    "          num_blocks_W=nblocksW_lasso, num_blocks_U=1, layer=None, Normalize_U=True, saveItr=False) \n",
    "# get SMAF results\n",
    "res_U, coln_U = analyse_U_W(U, W, X)\n",
    "\n",
    "# save U_ \n",
    "pd.DataFrame(U, columns=list(range(1, U.shape[1]+1)),index=sce.var.index).to_csv(\n",
    "    os.path.join(U_path, 'U.csv'))\n",
    "\n",
    "# Transform U results into DF\n",
    "df = pd.DataFrame(res_U).T ## .T added since it's 1D DF\n",
    "df.columns = coln_U\n",
    "\n",
    "# save U results as csv\n",
    "df.to_csv(path_or_buf=os.path.join(out_path, 'result_U.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7675a4a2",
   "metadata": {},
   "source": [
    "## Produce random As\n",
    "Here we produced random As with maxcomposition of 2,3,4\n",
    "\n",
    "n_A_each: n of random As produced per unique L0sum\n",
    "\n",
    "n_L0sum: n of unique L0 sum. Defined number of L0sum will be selected in desending order from the max L0sum.\n",
    "\n",
    "g: no of total genes\n",
    "\n",
    "m: n of composite channels\n",
    "\n",
    "n: [min,max] of channels per gene\n",
    "\n",
    "d_thresh: distance threshold per gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3da0c0a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random 18 As with L0sum between 24 and 32. 16 genes into 8 channels, max 2 channels per gene\n",
      "86 0\n",
      "Random 32 As with L0sum between 33 and 48. 16 genes into 8 channels, max 3 channels per gene\n",
      "260 6\n",
      "Random 32 As with L0sum between 49 and 64. 16 genes into 8 channels, max 4 channels per gene\n",
      "127 8\n"
     ]
    }
   ],
   "source": [
    "# produce Phi with maxcomposition of 2, 3, and 4\n",
    "Phi2 = produce_random_As(n_A_each=2, n_L0sum=9, m=8, n=(1,2), d_thresh=0.7, g=16)\n",
    "Phi3 = produce_random_As(n_A_each=2, n_L0sum=16, m=8, n=(1,3), d_thresh=0.7, g=16)\n",
    "Phi4 = produce_random_As(n_A_each=2, n_L0sum=16, m=8, n=(1,4), d_thresh=0.5, g=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28f3dd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine into 1 Phi \n",
    "Phi = Phi2 + Phi3 + Phi4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5075418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save As\n",
    "np.save(os.path.join(A_path,\"Phi.npy\"),np.array(Phi))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098981df",
   "metadata": {},
   "source": [
    "## Simulate decompression using random As\n",
    "\n",
    "ldaW_dc: error tolerance coefficient when decoding W from Y = AUW using lasso.\n",
    "\n",
    "nsr: noise_to_signal ratio when simulating Y from AX.\n",
    "\n",
    "u_id: id of U used to simulate decompression.\n",
    "\n",
    "wt: normalization weight of X (proteinwise) when simulating Y from AX.\n",
    "\n",
    "cur_ROI: ROI used for simulating decompression. Here we selected 25% of X (see above) so noted as \"percent 25\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "860a0829",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/test_cisi_imc_env/lib/python3.10/site-packages/scipy/spatial/distance.py:622: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n"
     ]
    }
   ],
   "source": [
    "ldaW_dc = 0.02\n",
    "nsr = 0    # no noise added when simluating Y\n",
    "u_id = 0   # only one U used\n",
    "wt = 0     # no normalization on sce_trainigA\n",
    "cur_ROI = \"25percent\" # ROI used for simulating decompression. \n",
    "\n",
    "sum_res_A = []  # general results for simlated decompression\n",
    "genewise_res_A = []  # proteinwise/cellwise correlation for simlated decompression\n",
    "Mincorr = []    # Minimum protein correlation (just for printing progress)\n",
    "\n",
    "for phi_id, phi in enumerate(Phi):\n",
    "    L0sum = np.linalg.norm(phi,ord = 0, axis = 1).sum()\n",
    "    maxcomposition = np.linalg.norm(phi,ord = 0, axis = 0).max()\n",
    "    X, Xhat, W, Y = simulate_A(sce_trainingA, U, phi, nsr, decoding_lasso_lda = ldaW_dc,\n",
    "                         outpath=None, THREADS=-1, layer=None, num_blocks=20)\n",
    "\n",
    "    res_A, coln_A, detail_A = analyse_decoding(phi,U,W,X,Xhat, name=\"\", detail=True)\n",
    "    res_A.extend([u_id,phi_id,L0sum,maxcomposition, nsr,ldaW_dc, wt, cur_ROI])\n",
    "    coln_A.extend([\"U_id\", \"A_id\",\"A_L0_sum\",\"maxcomposition\",\"inv_SNratio\",\"ldaW_simA\", \"Xnorm_weight\", \"ROI\"])\n",
    "    sum_res_A.append(res_A)\n",
    "    genewise_res_A.append(detail_A[0])\n",
    "\n",
    "    Mincorr = np.append(Mincorr,res_A[1])\n",
    "\n",
    "\n",
    "    if (phi_id+1)%100 == 0:\n",
    "        idx = np.argsort(Mincorr)  # get sorted index\n",
    "        best5 = Mincorr[idx[-5:][::-1]] # Best 5\n",
    "        print(\"current itr: {}, top5 mincorr:\".format(phi_id) ,['{:.3f}'.format(e) for e in best5])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131bad12",
   "metadata": {},
   "source": [
    "## save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b14bd46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform A results into DF\n",
    "df = pd.DataFrame(sum_res_A)\n",
    "df.columns = coln_A\n",
    "\n",
    "# save A results as csv\n",
    "df.to_csv(path_or_buf=os.path.join(out_path, 'result_A.csv'))\n",
    "\n",
    "\n",
    "# save genewise results as well\n",
    "df = pd.DataFrame(genewise_res_A)\n",
    "df.columns = sce.var.index\n",
    "df.to_csv(path_or_buf=os.path.join(out_path, 'result_A_genewise.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77af9dd7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_cisi_imc_env",
   "language": "python",
   "name": "test_cisi_imc_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
